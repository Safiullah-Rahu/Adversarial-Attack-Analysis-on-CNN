{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "badc3ff9",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "7ebae103",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from easydict import EasyDict\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D\n",
    "import sklearn as sk\n",
    "from cleverhans.tf2.attacks.basic_iterative_method import basic_iterative_method\n",
    "from cleverhans.tf2.attacks.projected_gradient_descent import projected_gradient_descent\n",
    "from cleverhans.tf2.attacks.fast_gradient_method import fast_gradient_method\n",
    "from cleverhans.tf2.attacks.carlini_wagner_l2 import carlini_wagner_l2\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7c86c3",
   "metadata": {},
   "source": [
    "### Create CNN Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "55e3fc92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"cnn_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_147 (Conv2D)         multiple                  12352     \n",
      "                                                                 \n",
      " conv2d_148 (Conv2D)         multiple                  295040    \n",
      "                                                                 \n",
      " conv2d_149 (Conv2D)         multiple                  409728    \n",
      "                                                                 \n",
      " dropout_49 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      " flatten_49 (Flatten)        multiple                  0         \n",
      "                                                                 \n",
      " dense_98 (Dense)            multiple                  16512     \n",
      "                                                                 \n",
      " dense_99 (Dense)            multiple                  1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 734,922\n",
      "Trainable params: 734,922\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class CNN(Model):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = Conv2D(64, 8, strides=(2, 2), activation=\"relu\", padding=\"same\")\n",
    "        self.conv2 = Conv2D(128, 6, strides=(2, 2), activation=\"relu\", padding=\"valid\")\n",
    "        self.conv3 = Conv2D(128, 5, strides=(1, 1), activation=\"relu\", padding=\"valid\")\n",
    "        self.dropout = Dropout(0.2)\n",
    "        self.flatten = Flatten()\n",
    "        self.dense1 = Dense(128, activation=\"relu\")\n",
    "        self.dense2 = Dense(10)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        \n",
    "        return self.dense2(x)\n",
    "\n",
    "model = CNN()\n",
    "model.build(input_shape=(None, 28, 28, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e0f3a0",
   "metadata": {},
   "source": [
    "### Load and Preprocess MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "d15c0a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist():\n",
    "    \"\"\"Load training and testing mnist data.\"\"\"\n",
    "\n",
    "    def convert_types(image, label):\n",
    "        image = tf.cast(image, tf.float32)\n",
    "        image /= 255\n",
    "        return image, label\n",
    "\n",
    "    dataset, info = tfds.load(\n",
    "        \"mnist\", \n",
    "        with_info=True, \n",
    "        as_supervised=True\n",
    "    )\n",
    "    \n",
    "    mnist_train, mnist_test = dataset[\"train\"], dataset[\"test\"]\n",
    "    mnist_train = mnist_train.map(convert_types).shuffle(10000).batch(128)\n",
    "    mnist_test = mnist_test.map(convert_types).batch(128)\n",
    "    \n",
    "    return EasyDict(train=mnist_train, test=mnist_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e98c0d",
   "metadata": {},
   "source": [
    "### Train and Evaluate CNN Architecture on Original Data and Adversarial Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "192922ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 5s 89us/step - loss: 0.4347\n",
      "60000/60000 [==============================] - 4s 66us/step - loss: 0.1502\n",
      "60000/60000 [==============================] - 4s 69us/step - loss: 0.1069\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.0846\n",
      "60000/60000 [==============================] - 3s 56us/step - loss: 0.0708\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0612\n",
      "60000/60000 [==============================] - 3s 58us/step - loss: 0.0540\n",
      "60000/60000 [==============================] - 3s 57us/step - loss: 0.0484\n",
      "10000/10000 [==============================] - 249s 25ms/step\n",
      "test acc on clean examples (%): 98.980\n",
      "Precision 1.0\n",
      "Recall 1.0\n",
      "f1_score 1.0\n",
      "test acc on FGM adversarial examples (%): 9.700\n",
      "Precision 0.2333333333333333\n",
      "Recall 0.275\n",
      "f1_score 0.23333333333333334\n",
      "test acc on CW adversarial examples (%): 66.240\n",
      "Precision 0.8518518518518517\n",
      "Recall 0.8611111111111112\n",
      "f1_score 0.8322751322751323\n",
      "test acc on BIM adversarial examples (%): 0.850\n",
      "Precision 0.0\n",
      "Recall 0.0\n",
      "f1_score 0.0\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 8\n",
    "eps = 0.3\n",
    "adv_train = False #Use adversarial training (on PGD adversarial examples).\n",
    "\n",
    "# Load training and test data\n",
    "data = load_mnist()\n",
    "model = CNN()\n",
    "loss_object = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "# Metrics to track the different accuracies.\n",
    "train_loss = tf.metrics.Mean(name=\"train_loss\")\n",
    "test_acc_clean = tf.metrics.SparseCategoricalAccuracy()\n",
    "test_acc_fgsm = tf.metrics.SparseCategoricalAccuracy()\n",
    "test_acc_pgd = tf.metrics.SparseCategoricalAccuracy()\n",
    "test_acc_bim = tf.metrics.SparseCategoricalAccuracy()\n",
    "test_acc_cw = tf.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def train_step(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(x)\n",
    "        loss = loss_object(y, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    train_loss(loss)\n",
    "\n",
    "# Train model with adversarial training\n",
    "for epoch in range(nb_epochs):\n",
    "    # keras like display of progress\n",
    "    progress_bar_train = tf.keras.utils.Progbar(60000)\n",
    "    for (x, y) in data.train:\n",
    "        if adv_train:\n",
    "            # Replace clean example with adversarial example for adversarial training\n",
    "            x = projected_gradient_descent(model, x, eps, 0.01, 40, np.inf)\n",
    "        train_step(x, y)\n",
    "        progress_bar_train.add(x.shape[0], values=[(\"loss\", train_loss.result())])\n",
    "\n",
    "# Evaluate on clean and adversarial data\n",
    "progress_bar_test = tf.keras.utils.Progbar(10000)\n",
    "for x, y in data.test:\n",
    "    y_pred = model(x)\n",
    "    test_acc_clean(y, y_pred)\n",
    "\n",
    "    x_fgm = fast_gradient_method(model, x, eps, np.inf)\n",
    "    y_pred_fgm = model(x_fgm)\n",
    "    test_acc_fgsm(y, y_pred_fgm)\n",
    "    \n",
    "    x_cw = carlini_wagner_l2(model, x, max_iterations=100,\n",
    "                                       binary_search_steps=2,\n",
    "                                       learning_rate=1e-2,\n",
    "                                       initial_const=1,)\n",
    "    y_pred_cw = model(x_cw)\n",
    "    test_acc_cw(y, y_pred_cw)\n",
    "\n",
    "    bim = basic_iterative_method(model, x, eps, 0.05, 10, np.inf)\n",
    "    y_pred_bim = model(bim)\n",
    "    test_acc_bim(y, y_pred_bim)\n",
    "\n",
    "\n",
    "    \n",
    "    progress_bar_test.add(x.shape[0])\n",
    "\n",
    "# Displaying various metrics for evaluation\n",
    "print(\"test acc on clean examples (%): {:.3f}\".format(test_acc_clean.result() * 100)) \n",
    "y_pred = np.argmax(y_pred,1)\n",
    "print(\"Precision\", sk.metrics.precision_score(y, y_pred, average=\"macro\"))\n",
    "print(\"Recall\", sk.metrics.recall_score(y, y_pred, average=\"macro\"))\n",
    "print(\"f1_score\", sk.metrics.f1_score(y, y_pred, average=\"macro\"))\n",
    " \n",
    "print(\"test acc on FGM adversarial examples (%): {:.3f}\".format(test_acc_fgsm.result() * 100))\n",
    "y_pred_fgm = np.argmax(y_pred_fgm,1)\n",
    "print(\"Precision\", sk.metrics.precision_score(y, y_pred_fgm, average=\"macro\"))\n",
    "print(\"Recall\", sk.metrics.recall_score(y, y_pred_fgm, average=\"macro\"))\n",
    "print(\"f1_score\", sk.metrics.f1_score(y, y_pred_fgm, average=\"macro\"))\n",
    "\n",
    "print(\"test acc on CW adversarial examples (%): {:.3f}\".format(test_acc_cw.result() * 100))\n",
    "y_pred_cw = np.argmax(y_pred_cw,1)\n",
    "print(\"Precision\", sk.metrics.precision_score(y, y_pred_cw, average=\"macro\"))\n",
    "print(\"Recall\", sk.metrics.recall_score(y, y_pred_cw, average=\"macro\"))\n",
    "print(\"f1_score\", sk.metrics.f1_score(y, y_pred_cw, average=\"macro\"))\n",
    "\n",
    "print(\"test acc on BIM adversarial examples (%): {:.3f}\".format(test_acc_bim.result() * 100))\n",
    "y_pred_bim = np.argmax(y_pred_bim,1)\n",
    "print(\"Precision\", sk.metrics.precision_score(y, y_pred_bim, average=\"macro\"))\n",
    "print(\"Recall\", sk.metrics.recall_score(y, y_pred_bim, average=\"macro\"))\n",
    "print(\"f1_score\", sk.metrics.f1_score(y, y_pred_bim, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5eb2db4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
